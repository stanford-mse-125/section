{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCKuFp0z9Iq9"
   },
   "source": [
    "# Discussion 2: More Pandas and Sampling\n",
    "\n",
    "Welcome to MS&E 125 Discussions! Discussions are an opportunity to get hands-on experience with material from lecture, as well as prepare you for completing the homework assignments. Completing the discussions is optional, and we will not be collecting them. However, we strongly encourage you to work through the discussions, as we feel that they are the best way to learn the material. Additionally, attending the discussion sections gives you the opportunity to get support from the course TAs as needed and help you stay on top of the material.\n",
    "\n",
    "The goal is for each discussion notebook to be fully contained so that you can work through the discussions on your own. When completing a discussion, you should work through the whole notebook, reading all text components and running all code cells. Additionally, there will be some exercises in the notebook for you to complete to make sure you are understanding the material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on CodeSquire**\n",
    "\n",
    "As you've seen in lectures, we can use an AI tool called CodeSquire to speed up coding workflow. CodeSquire.ai is an AI code writing assistant for data professionals. The Codesquire engine is using large language models to write entire functions and complex logic. It adapts to your code writing style and uses your code as well as code comments to understand the intent and generate the code adapted to your use case.\n",
    "\n",
    "*Getting started*: You can download the [google chrome extension](https://chrome.google.com/webstore/detail/codesquireai/ikldibchjbalnngafojhlnbddkehoooc) and access the [documentation](https://app.codesquire.ai/) to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju3_Wicz-jr5"
   },
   "source": [
    "## Pandas Operations\n",
    "\n",
    "In week 1, we focused on Pandas fundamentals like reading and writing data, editing, and subsetting. In this discussion, we will introduce some more complex but important Pandas operations, including the `groupby` operation and merging/joining data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG1IyBWBGJ0n"
   },
   "source": [
    "Today we're going to work with the Forbes Richest People Dataset, which is a collection of data related to the world's wealthiest individuals. It includes information about the billionaire's origins, current net worth, and age. The dataset is regularly updated by Forbes and is widely used by researchers, analysts, and journalists to study trends in wealth accumulation, income inequality, and economic growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZEr7I3UBKDUW"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "1xMmUuUP9Gdk",
    "outputId": "92eb859d-6b61-4384-e121-8e03063a704f"
   },
   "outputs": [],
   "source": [
    "rich = pd.read_csv(\"https://raw.githubusercontent.com/stanford-mse-125/section/main/Discussions/data/forbes_richman.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Net Worth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>Source</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$219 B</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$171 B</td>\n",
       "      <td>58.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$158 B</td>\n",
       "      <td>73.0</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$129 B</td>\n",
       "      <td>66.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>$118 B</td>\n",
       "      <td>91.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>2505</td>\n",
       "      <td>Guo Jiangang</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>55.0</td>\n",
       "      <td>China</td>\n",
       "      <td>household appliances</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>2506</td>\n",
       "      <td>Vera Rechulski Santo Domingo</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>beer</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>2507</td>\n",
       "      <td>Mike Speiser</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>51.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>software</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>2508</td>\n",
       "      <td>Yao Liangbo</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>53.0</td>\n",
       "      <td>China</td>\n",
       "      <td>furniture retailing</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>2509</td>\n",
       "      <td>Ihor Kolomoyskyy</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>banking, investments</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2509 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank                          Name Net Worth   Age        Country  \\\n",
       "0        1                     Elon Musk    $219 B  50.0  United States   \n",
       "1        2                    Jeff Bezos    $171 B  58.0  United States   \n",
       "2        3      Bernard Arnault & family    $158 B  73.0         France   \n",
       "3        4                    Bill Gates    $129 B  66.0  United States   \n",
       "4        5                Warren Buffett    $118 B  91.0  United States   \n",
       "...    ...                           ...       ...   ...            ...   \n",
       "2504  2505                  Guo Jiangang      $1 B  55.0          China   \n",
       "2505  2506  Vera Rechulski Santo Domingo      $1 B  73.0         Brazil   \n",
       "2506  2507                  Mike Speiser      $1 B  51.0  United States   \n",
       "2507  2508                   Yao Liangbo      $1 B  53.0          China   \n",
       "2508  2509              Ihor Kolomoyskyy      $1 B  59.0        Ukraine   \n",
       "\n",
       "                    Source               Industry  \n",
       "0            Tesla, SpaceX             Automotive  \n",
       "1                   Amazon             Technology  \n",
       "2                     LVMH       Fashion & Retail  \n",
       "3                Microsoft             Technology  \n",
       "4       Berkshire Hathaway  Finance & Investments  \n",
       "...                    ...                    ...  \n",
       "2504  household appliances          Manufacturing  \n",
       "2505                  beer        Food & Beverage  \n",
       "2506              software             Technology  \n",
       "2507   furniture retailing       Fashion & Retail  \n",
       "2508  banking, investments            Diversified  \n",
       "\n",
       "[2509 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       219.0\n",
       "1       171.0\n",
       "2       158.0\n",
       "3       129.0\n",
       "4       118.0\n",
       "        ...  \n",
       "2504      1.0\n",
       "2505      1.0\n",
       "2506      1.0\n",
       "2507      1.0\n",
       "2508      1.0\n",
       "Name: Net Worth, Length: 2509, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Net worth column to make it numeric\n",
    "net_worth = rich[\"Net Worth\"].str.lstrip(\"$\") # Strip string of '$' sign\n",
    "net_worth = net_worth.str.rstrip(\" B\") # Strip string of 'B' at the end \n",
    "rich[\"Net Worth\"] = pd.to_numeric(net_worth) # Convert from string data type to numeric\n",
    "rich[\"Net Worth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxZr89m1KhoF"
   },
   "source": [
    "### **Grouping**\n",
    "\n",
    "Let's say that we are interested in looking at the average net worth (in billions) by country in our dataset. For an individual country, it is easy to subset the data using tools from week 1 and calculate the mean on the subset, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.728260869565218"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk = rich.loc[rich[\"Country\"] == \"United Kingdom\", \"Net Worth\"]\n",
    "uk.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAJCaSTcLUDY"
   },
   "source": [
    "However, if we want to calculate this mean for *all* countries in the dataset at the same time, it would be very slow and tedious to do the above for every country individually. This is where the `groupby` operation comes in handy. In a `groupby` operation, we group together all rows which share the same value of the ID variables, and then perform some aggregating operation over the remaining variables. \n",
    "\n",
    "The below image illustrates how a group by operation would work if we were trying to calculate average price for each genre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://learnsql.com/blog/group-by-in-sql-explained/GROUP_BY-avg.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how we can use a `groupby` operation to get the average net worth by country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_XIWJalM9av",
    "outputId": "f872a0e9-9874-4c74-9d37-9f2a7a0ce22b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Algeria           5.100000\n",
       "Argentina         2.333333\n",
       "Australia         4.655814\n",
       "Austria           5.609091\n",
       "Barbados          1.700000\n",
       "                    ...   \n",
       "United Kingdom    3.728261\n",
       "United States     6.562990\n",
       "Uruguay           1.500000\n",
       "Venezuela         3.500000\n",
       "Vietnam           2.500000\n",
       "Name: Net Worth, Length: 74, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rich.groupby(\"Country\").mean()[\"Net Worth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sort this series to eyeball what the top 5 countries are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "France           12.817500\n",
       "Nigeria           9.400000\n",
       "United States     6.562990\n",
       "Ireland           6.085714\n",
       "Colombia          6.025000\n",
       "                   ...    \n",
       "Slovakia          1.500000\n",
       "Uruguay           1.500000\n",
       "Nepal             1.500000\n",
       "Hungary           1.250000\n",
       "Estonia           1.200000\n",
       "Name: Net Worth, Length: 74, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rich.groupby(\"Country\").mean()[\"Net Worth\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJLHqh_1Na_t"
   },
   "source": [
    "Once we do a `groupby` operation in Pandas, we can easily do other aggregating operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ghB4iluoOWVy"
   },
   "outputs": [],
   "source": [
    "country_groups = rich.groupby(\"Country\")[\"Net Worth\"]\n",
    "\n",
    "# Get standard deviation for each country\n",
    "country_stds = country_groups.std()\n",
    "\n",
    "# Get the number of rows for each country\n",
    "country_counts = country_groups.count()\n",
    "\n",
    "# Can do custom aggregation functions using \n",
    "# e.g. get mean logarithm net worth\n",
    "country_mean_log_net_worth = country_groups.apply(lambda x: np.log(x).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqtK0LONRWlV"
   },
   "source": [
    "It's also possible to group by more than 1 column. For example, if we wanted to get the mean net worth for individuals from the same country and industry, we could do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16a3heseRqNp",
    "outputId": "3b179abd-7f0e-462b-a834-cd381f6203cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Industry    Country       \n",
       "Automotive  Australia          2.600000\n",
       "            Austria            1.200000\n",
       "            China              7.358824\n",
       "            Germany            7.700000\n",
       "            Hong Kong         18.700000\n",
       "                                ...    \n",
       "Telecom     Russia             1.450000\n",
       "            South Korea        2.400000\n",
       "            Turkey             1.100000\n",
       "            United Kingdom     2.150000\n",
       "            United States      2.875000\n",
       "Name: Net Worth, Length: 440, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now group by symbol and month\n",
    "rich.groupby([\"Industry\", \"Country\"]).mean()[\"Net Worth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU0_mBnNuCst"
   },
   "source": [
    "**Exercise**\n",
    "* Calculate the average age of wealthy individuals from each industry. \n",
    "* Count the number of wealthy individuals in each industry.\n",
    "* Find the top 5 countries with the greatest total net worth. \n",
    "* *Challenge* : Find the difference in net worth between the most wealthy and second most wealthy person in each industry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzgsAOHARC3L"
   },
   "source": [
    "### **Joining and Merging**\n",
    "\n",
    "Often it is useful to combine multiple dataframes into one dataframe. Luckily there are several ways to do this in Pandas. Let's start with the following 3 dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IL3MEEbcTLOm"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"A\": [0, 1, 2],\n",
    "    \"B\": [3, 4, 5],\n",
    "    \"C\": [6, 7, 8],\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    \"D\": [\"a\", \"b\", \"c\"],\n",
    "    \"E\": [\"d\", \"e\", \"f\"],\n",
    "    \"F\": [\"g\", \"h\", \"i\"],\n",
    "})\n",
    "df3 = pd.DataFrame({\n",
    "    \"A\": [2, 0, -2],\n",
    "    \"D\": [-1, -2, -3]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMshWjsEcd1z"
   },
   "source": [
    "The most straightforward way to combine dataframes in pandas is to concatenate them using `pd.concat`. Concatenation can happen *vertically*, i.e. stacking dataframes on top of each other, or *horizontally*, i.e. combining side-by-side. We can see this in action with our test dataframes above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72WcSXfJjDE8",
    "outputId": "dba61785-cda9-4660-ea56-9da6c6a26cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical stack\n",
      "   A  B   C\n",
      "0  0  3   6\n",
      "1  1  4   7\n",
      "2  2  5   8\n",
      "0  3  6   9\n",
      "1  4  7  10\n",
      "2  5  8  11\n",
      "\n",
      "Horizontal Stack\n",
      "   A  B  C  D  E  F\n",
      "0  0  3  6  a  d  g\n",
      "1  1  4  7  b  e  h\n",
      "2  2  5  8  c  f  i\n"
     ]
    }
   ],
   "source": [
    "# Vertically stack df1 and (df1 + 3)\n",
    "print(\"Vertical stack\")\n",
    "print(pd.concat([df1, df1 + 3], axis=0))\n",
    "\n",
    "# Horizontally stack df1 and df2\n",
    "print(\"\\nHorizontal Stack\")\n",
    "print(pd.concat([df1, df2], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AWdNJNDkPxT"
   },
   "source": [
    "Notice the difference in the code for vertical and horizontal stacking: the use of the `axis` parameter. In general in Pandas, *axis 0 goes across rows, and axis 1 goes across columns*. Thus, we use `pd.concat(dfs, axis=0)` to concatenate rows, i.e. concatenate vertically, and `pd.concat(dfs, axis=1)` to concatenate columns, i.e. concatenate horizontally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NSZVZ4mmHWV"
   },
   "source": [
    "Sometimes, though, we want to do more than simply concatenate. Specifically, we sometimes want to *join* the dataframes based on the value of one or more columns such as in the image below. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://r4ds.hadley.nz/diagrams/join/inner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of joining `df1` and `df3` on the \"A\" column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "oM0yTxKLnS2f",
    "outputId": "7a3e506d-affb-4cb1-d70b-f56d32bf6ee7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  0  3  6 -2\n",
       "1  2  5  8 -1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df3, on=\"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `pd.merge` found rows in `df1` and `df3` where A=2 and A=0, and matched these rows together. One row in each original dataframe, however, was dropped because there was no matching row in the other dataframe. This behavior occured because of the type of join we performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qmGCID3om4g"
   },
   "source": [
    "There are 4 typical types of joins:\n",
    "\n",
    "- **Inner**: keep rows where the ID columns are matched in both dataframes. This is the default in `pd.merge` and what was done in the above example.\n",
    "- **Left**: includes all rows from inner join, but also includes rows from the \"left\" (first) dataframe that do not have matches. These unmatched rows are filled with NAs for all columns from the right dataframe.\n",
    "- **Right**: same as left join, but reversing the role of the left (first) and right (second) dataframes.\n",
    "- **Outer**: keep all rows from both dataframes, replacing with NAs where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.geeksforgeeks.org/wp-content/uploads/joinimages.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlling the type of join is easy to do using the `how` parameter in `pd.merge`. Some examples are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HN3b3A8DqhBm",
    "outputId": "7591297a-40d9-4919-ca8c-ab7ced099456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Join\n",
      "   A  B  C  D\n",
      "0  0  3  6 -2\n",
      "1  2  5  8 -1\n",
      "\n",
      "Left Join\n",
      "   A  B  C    D\n",
      "0  0  3  6 -2.0\n",
      "1  1  4  7  NaN\n",
      "2  2  5  8 -1.0\n",
      "\n",
      "Right Join\n",
      "   A    B    C  D\n",
      "0  2  5.0  8.0 -1\n",
      "1  0  3.0  6.0 -2\n",
      "2 -2  NaN  NaN -3\n",
      "\n",
      "Outer Join\n",
      "   A    B    C    D\n",
      "0  0  3.0  6.0 -2.0\n",
      "1  1  4.0  7.0  NaN\n",
      "2  2  5.0  8.0 -1.0\n",
      "3 -2  NaN  NaN -3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Inner Join\")\n",
    "print(pd.merge(df1, df3, on=\"A\", how=\"inner\"))\n",
    "\n",
    "print(\"\\nLeft Join\")\n",
    "print(pd.merge(df1, df3, on=\"A\", how=\"left\"))\n",
    "\n",
    "print(\"\\nRight Join\")\n",
    "print(pd.merge(df1, df3, on=\"A\", how=\"right\"))\n",
    "\n",
    "print(\"\\nOuter Join\")\n",
    "print(pd.merge(df1, df3, on=\"A\", how=\"outer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDEcFsUlhn56"
   },
   "source": [
    "**EXERCISE** Let's say we're interested in joining the iso country code onto our `rich` dataset. Create a new version of the `rich` dataset with the `Alpha-2 code` column from `iso_codes` joined onto it. Think carefully about which type of join would be most appropriate.\n",
    "\n",
    "Hint: The resulting dataset should be of shape (2509, 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data to get you started\n",
    "iso_codes = pd.read_csv(\"https://raw.githubusercontent.com/stanford-mse-125/section/main/Discussions/data/wikipedia-iso-country-codes.csv\")\n",
    "iso_codes = iso_codes.rename(columns={\"English short name lower case\":\"Country\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxGWl4lYhZin"
   },
   "source": [
    "### **Sampling**\n",
    "\n",
    "We're now going to switch gears and talk about sampling. Sampling is an extremely important tool for any statistician, and is the workhorse of several very important data science topics including [Monte Carlo methods](https://en.wikipedia.org/wiki/Monte_Carlo_method#:~:text=Monte%20Carlo%20methods%2C%20or%20Monte,might%20be%20deterministic%20in%20principle.), [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)), and [numerical linear algebra](https://en.wikipedia.org/wiki/Numerical_linear_algebra). *Sampling* can be defined as the process of collecting a random set of observations from some population. What the population is that we are sampling from is most crucial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d8ZkTZoqozb"
   },
   "source": [
    "Let's start by looking at the function `pd.sample`, which is used to draw samples from a user-defined fixed population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw 2 random samples from l\n",
      "   x\n",
      "2  2\n",
      "3  3\n",
      "\n",
      "Draw 10 random samples with replacement from l\n",
      "   x\n",
      "1  1\n",
      "4  4\n",
      "0  0\n",
      "1  1\n",
      "3  3\n",
      "4  4\n",
      "1  1\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "\n",
      "Draw 5 random samples with replacement and with unequal probabilities from l\n",
      "   x    p\n",
      "0  0  0.8\n",
      "0  0  0.8\n",
      "0  0  0.8\n",
      "0  0  0.8\n",
      "0  0  0.8\n",
      "0  0  0.8\n",
      "0  0  0.8\n",
      "0  0  0.8\n",
      "0  0  0.8\n",
      "0  0  0.8\n"
     ]
    }
   ],
   "source": [
    "# Generate an array from 0 to 4\n",
    "l = pd.DataFrame({\n",
    "    \"x\": list(range(5))\n",
    "})\n",
    "\n",
    "print(\"Draw 2 random samples from l\")\n",
    "print(l.sample(n=2, random_state=10))\n",
    "\n",
    "print(\"\\nDraw 10 random samples with replacement from l\")\n",
    "print(l.sample(n=10, replace=True, random_state=10))\n",
    "\n",
    "print(\"\\nDraw 5 random samples with replacement and with unequal probabilities from l\")\n",
    "l[\"p\"] = [0.8, 0.05, 0.05, 0.05, 0.05]\n",
    "print(l.sample(n=10, replace=True, weights=\"p\", random_state=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh5g38-9wphF"
   },
   "source": [
    "The other most common type of sampling is sampling from known probability distributions. This is very easy to do using NumPy. Here are a few examples of drawing from common probability distributions using `np.random`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1qjkuT1ycQQ",
    "outputId": "31d16033-b630-4515-c83e-47aeae0a77ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples from the standard Normal distribution\n",
      "[ 1.3315865   0.71527897 -1.54540029 -0.00838385  0.62133597]\n",
      "\n",
      "Samples from a Normal distribution with mean -2 and standard deviation 3\n",
      "[-4.16025668 -1.20346524 -1.67435442 -1.98712571 -2.52380063]\n",
      "\n",
      "Samples from a Binomial distribution with n=10, p=0.5\n",
      "[6 5 6 4 7]\n",
      "\n",
      "Samples from a Bernoulli distribution with p=0.5\n",
      "[1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Set seed to ensure reproducible results. This performs the same role as the `random_state` argument in `pd.sample`\n",
    "np.random.seed(10)\n",
    "\n",
    "print(\"Samples from the standard Normal distribution\")\n",
    "print(np.random.normal(size=5))\n",
    "\n",
    "print(\"\\nSamples from a Normal distribution with mean -2 and standard deviation 3\")\n",
    "print(np.random.normal(loc=-2, scale=3, size=5))\n",
    "\n",
    "print(\"\\nSamples from a Binomial distribution with n=10, p=0.5\")\n",
    "print(np.random.binomial(n=10, p=0.5, size=5))\n",
    "\n",
    "# Use binomial function to sample Bernoulli as well\n",
    "print(\"\\nSamples from a Bernoulli distribution with p=0.5\")\n",
    "print(np.random.binomial(n=1, p=0.5, size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eTPD5fi2HiB"
   },
   "source": [
    "**EXERCISE** \n",
    "\n",
    "- Randomly sample 10 wealthy individuals without replacement from the `rich` dataset. Print out the mean of these individuals.\n",
    "- Do the above 1000 times, which time storing the mean of the 10 selected individuals.\n",
    "- Make a plot to visualize the distribution of the 1000 means."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
